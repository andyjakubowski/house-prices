{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from scipy import stats\n",
    "from pandas.plotting import scatter_matrix\n",
    "import subprocess\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Kaggle submission file\n",
    "def submission_df(y_pred):\n",
    "    X_test = load_x_test()\n",
    "    return pd.DataFrame(y_pred, index=X_test.index, columns=[\"SalePrice\"])\n",
    "\n",
    "def save_submission_file(y_pred, filename):\n",
    "    df = submission_df(y_pred)\n",
    "    path = \"./\" + filename\n",
    "\n",
    "    try:\n",
    "        df.to_csv(path)\n",
    "    except Exception:\n",
    "        print(\"Couldnâ€™t save submission.\")\n",
    "    else:\n",
    "        print(\"Submission saved.\")\n",
    "        \n",
    "# Submit score to Kaggle\n",
    "def submit_score_to_kaggle(y_pred, filename, message):\n",
    "    save_submission_file(y_pred, filename)\n",
    "\n",
    "    completed_process = subprocess.run(\n",
    "        [\n",
    "            \"kaggle\",\n",
    "            \"competitions\",\n",
    "            \"submit\",\n",
    "            \"-c\",\n",
    "            \"house-prices-advanced-regression-techniques\",\n",
    "            \"-f\",\n",
    "            filename,\n",
    "            \"-m\",\n",
    "            message\n",
    "        ], \n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(completed_process.stdout)\n",
    "    \n",
    "def load_train_data(split=True):\n",
    "    target = \"SalePrice\"\n",
    "    data = pd.read_csv(\"./train.csv\", index_col=\"Id\")\n",
    "    features = [column for column in data.columns if not column == target]\n",
    "    print(\"load_train_data: done\")\n",
    "    \n",
    "    if split:\n",
    "        return data[features], data[target]\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "def load_x_test():\n",
    "    return pd.read_csv(\"./test.csv\", index_col=\"Id\");\n",
    "\n",
    "def load_y_true():\n",
    "    y_true = pd.read_csv(\"./solution.csv\", index_col=\"Id\")\n",
    "    return y_true\n",
    "\n",
    "def load_test_data(split=True):\n",
    "    X_test = pd.read_csv(\"./test.csv\", index_col=\"Id\")\n",
    "    y_test = load_y_true()\n",
    "    print(\"load_test_data: done\")\n",
    "    \n",
    "    if split:\n",
    "        return X_test, y_test\n",
    "    else:\n",
    "        return pd.concat([X_test, y_test], axis=\"columns\")\n",
    "    \n",
    "def split_features_target(df, target=\"SalePrice\"):\n",
    "    features = [column for column in df.columns if not column == target]\n",
    "    return df[features], df[target]\n",
    "\n",
    "def root_mean_squared_log_error(y_true, y_pred, transform_negative_predictions=False):\n",
    "    if transform_negative_predictions:\n",
    "        y_pred_tr = [max(prediction, 0) for prediction in y_pred]\n",
    "    else:\n",
    "        y_pred_tr = y_pred\n",
    "    \n",
    "    # same as np.sqrt(np.mean(np.power(np.log(np.array(y_pred_tr) + 1) - np.log(np.array(y_true) + 1), 2)))\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred_tr))\n",
    "\n",
    "rmsle = root_mean_squared_log_error\n",
    "\n",
    "def kaggle_score(y_pred, transform_negative_predictions=False, y_log_transformed=False):\n",
    "    y_true = load_y_true()\n",
    "    \n",
    "    if y_log_transformed:\n",
    "        y_pred = np.exp(y_pred)\n",
    "\n",
    "    score = root_mean_squared_log_error(y_true, y_pred, transform_negative_predictions=transform_negative_predictions)\n",
    "    return score\n",
    "\n",
    "def print_kaggle_score(y_pred):\n",
    "    y_true = load_y_true()\n",
    "    score = kaggle_score(y_pred)\n",
    "    print(\"The score is %.5f\" % score)\n",
    "    \n",
    "# Make your own RMSLE (root mean square log error) scorer\n",
    "rmsle_scorer = make_scorer(root_mean_squared_log_error, greater_is_better=False, transform_negative_predictions=True)\n",
    "\n",
    "def get_pipe(model):\n",
    "    numeric_pipe = Pipeline([\n",
    "        ('impute_missing_numeric_values', SimpleImputer(strategy=\"median\")),\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipe = Pipeline([\n",
    "        ('impute_missing_categorical_values', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('standard_scaler', OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessing = ColumnTransformer([\n",
    "        ('numeric', numeric_pipe, make_column_selector(dtype_include=np.number)),\n",
    "        ('categorical', categorical_pipe, make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    n_jobs=-1)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "def fit_evaluate(model, feature_engineered=False, ft_instructions=None):\n",
    "    if feature_engineered:\n",
    "        X_train, y_train, X_test = load_engineered_data(ft_instructions=ft_instructions)\n",
    "    else:\n",
    "        X_train, y_train = load_train_data()\n",
    "        X_test, _ = load_test_data()\n",
    "\n",
    "    pipe = get_pipe(model)\n",
    "    pipe.fit(X_train, y_train)    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    if feature_engineered:\n",
    "        score = kaggle_score(y_pred, y_log_transformed=True)\n",
    "    else:\n",
    "        score = kaggle_score(y_pred)\n",
    "    \n",
    "    result = {\n",
    "        \"model\": type(model).__name__,\n",
    "        \"kaggle_score\": score,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"fitted_estimator\": pipe,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def compare_models(models, feature_engineered=False, ft_instructions=None):\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        if feature_engineered:\n",
    "            result = fit_evaluate(model, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "        else:\n",
    "            result = fit_evaluate(model)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "def compute_cv_scores(model):\n",
    "    X_train, y_train = load_train_data()\n",
    "    X_test, _ = load_test_data()\n",
    "    pipe = get_pipe(model)\n",
    "    return cross_val_score(pipe, X_train, y_train, scoring=rmsle_scorer)\n",
    "\n",
    "models = [\n",
    "    RandomForestRegressor(random_state=42),\n",
    "#     LinearRegression(),\n",
    "    Ridge(),\n",
    "    RidgeCV(),\n",
    "    KernelRidge(),\n",
    "    LassoCV(),\n",
    "    ElasticNet(),\n",
    "    SGDRegressor(),\n",
    "    lgb.LGBMRegressor(),\n",
    "    xgb.XGBRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submit_score_to_kaggle(np.exp(results[8][\"y_pred\"]),\n",
    "#                       \"submission_LGBMRegressor_y_log.csv\",\n",
    "#                       \"Second try with lgb, the only difference is y_train was log-transformed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of cross val scoring with this setup\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "# scores = compute_cv_scores(rf)\n",
    "# print(f\"mean score: {np.mean(-scores)}, all cv scores:{-scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_log(y_train):\n",
    "    return np.log(y_train)\n",
    "\n",
    "def order_categoricals(X):\n",
    "    return X.replace({ \"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                        \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                        \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                        \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                        \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                        \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                        \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                        \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "                        \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "                        \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                        \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                        \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                        \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}})\n",
    "\n",
    "def add_simplification_features(X_train, X_test):\n",
    "    ten_to_three = {\n",
    "        1 : 1, 2 : 1, 3 : 1, # bad\n",
    "        4 : 2, 5 : 2, 6 : 2, # average\n",
    "        7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "    }\n",
    "\n",
    "    five_to_three = {\n",
    "        1 : 1, # bad\n",
    "        2 : 1, 3 : 1, # average\n",
    "        4 : 2, 5 : 2 # good\n",
    "    }\n",
    "\n",
    "    eight_to_four = {\n",
    "        1 : 1, 2 : 1, # bad\n",
    "        3 : 2, 4 : 2, # major\n",
    "        5 : 3, 6 : 3, 7 : 3, # minor\n",
    "        8 : 4 # typical\n",
    "    }\n",
    "\n",
    "    six_to_three = {\n",
    "        1 : 1, # unfinished\n",
    "        2 : 1, 3 : 1, # rec room\n",
    "        4 : 2, 5 : 2, 6 : 2 # living quarters\n",
    "    }\n",
    "\n",
    "    for df in (X_train, X_test):\n",
    "        df[\"SimplOverallQual\"] = df.OverallQual.replace(ten_to_three)\n",
    "        df[\"SimplOverallCond\"] = df.OverallCond.replace(ten_to_three)\n",
    "        df[\"SimplPoolQC\"] = df.PoolQC.replace(five_to_three)\n",
    "        df[\"SimplGarageCond\"] = df.GarageCond.replace(five_to_three)\n",
    "        df[\"SimplGarageQual\"] = df.GarageQual.replace(five_to_three)\n",
    "        df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace(five_to_three)\n",
    "        df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace(five_to_three)\n",
    "        df[\"SimplFunctional\"] = df.Functional.replace(eight_to_four)\n",
    "        df[\"SimplKitchenQual\"] = df.KitchenQual.replace(five_to_three)\n",
    "        df[\"SimplHeatingQC\"] = df.HeatingQC.replace(five_to_three)\n",
    "        df[\"SimplBsmtFinType1\"] = df.BsmtFinType1.replace(six_to_three)\n",
    "        df[\"SimplBsmtFinType2\"] = df.BsmtFinType2.replace(six_to_three)\n",
    "        df[\"SimplBsmtCond\"] = df.BsmtCond.replace(five_to_three)\n",
    "        df[\"SimplBsmtQual\"] = df.BsmtQual.replace(five_to_three)\n",
    "        df[\"SimplExterCond\"] = df.ExterCond.replace(five_to_three)\n",
    "        df[\"SimplExterQual\"] = df.ExterQual.replace(five_to_three)\n",
    "        \n",
    "def add_totalizer_features(X_train, X_test):\n",
    "    for df in (X_train, X_test):    \n",
    "        # Overall quality of the house\n",
    "        df[\"OverallGrade\"] = df[\"OverallQual\"] * df[\"OverallCond\"]\n",
    "        # Overall quality of the garage\n",
    "        df[\"GarageGrade\"] = df[\"GarageQual\"] * df[\"GarageCond\"]\n",
    "        # Overall quality of the exterior\n",
    "        df[\"ExterGrade\"] = df[\"ExterQual\"] * df[\"ExterCond\"]\n",
    "        # Overall kitchen score\n",
    "        df[\"KitchenScore\"] = df[\"KitchenAbvGr\"] * df[\"KitchenQual\"]\n",
    "        # Overall fireplace score\n",
    "        df[\"FireplaceScore\"] = df[\"Fireplaces\"] * df[\"FireplaceQu\"]\n",
    "        # Overall garage score\n",
    "        df[\"GarageScore\"] = df[\"GarageArea\"] * df[\"GarageQual\"]\n",
    "        # Overall pool score\n",
    "        df[\"PoolScore\"] = df[\"PoolArea\"] * df[\"PoolQC\"]\n",
    "        # Simplified overall quality of the house\n",
    "        df[\"SimplOverallGrade\"] = df[\"SimplOverallQual\"] * df[\"SimplOverallCond\"]\n",
    "        # Simplified overall quality of the exterior\n",
    "        df[\"SimplExterGrade\"] = df[\"SimplExterQual\"] * df[\"SimplExterCond\"]\n",
    "        # Simplified overall pool score\n",
    "        df[\"SimplPoolScore\"] = df[\"PoolArea\"] * df[\"SimplPoolQC\"]\n",
    "        # Simplified overall garage score\n",
    "        df[\"SimplGarageScore\"] = df[\"GarageArea\"] * df[\"SimplGarageQual\"]\n",
    "        # Simplified overall fireplace score\n",
    "        df[\"SimplFireplaceScore\"] = df[\"Fireplaces\"] * df[\"SimplFireplaceQu\"]\n",
    "        # Simplified overall kitchen score\n",
    "        df[\"SimplKitchenScore\"] = df[\"KitchenAbvGr\"] * df[\"SimplKitchenQual\"]\n",
    "        # Total number of bathrooms\n",
    "        df[\"TotalBath\"] = df[\"BsmtFullBath\"] + (0.5 * df[\"BsmtHalfBath\"]) + \\\n",
    "        df[\"FullBath\"] + (0.5 * df[\"HalfBath\"])\n",
    "        # Total SF for house (incl. basement)\n",
    "        df[\"AllSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n",
    "        # Total SF for 1st + 2nd floors\n",
    "        df[\"AllFlrsSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "        # Total SF for porch\n",
    "        df[\"AllPorchSF\"] = df[\"OpenPorchSF\"] + df[\"EnclosedPorch\"] + df[\"3SsnPorch\"] + df[\"ScreenPorch\"] + df['WoodDeckSF']\n",
    "        # Has masonry veneer or not\n",
    "        df[\"HasMasVnr\"] = df.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \"Stone\" : 1, \"None\" : 0})\n",
    "        # House completed before sale or not\n",
    "        df[\"BoughtOffPlan\"] = df.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n",
    "                                                            \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "        df['YrBltAndRemod']=df['YearBuilt']+df['YearRemodAdd']\n",
    "        df['TotalSF']=df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "        df['Total_sqr_footage'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'] + df['1stFlrSF'] + df['2ndFlrSF'])\n",
    "        df['haspool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        df['has2ndfloor'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        df['hasgarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        df['hasbsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        df['hasfireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        \n",
    "def add_polynomial_features(X_train, X_test):\n",
    "    feat1 = [\"OverallQual\",\"AllSF\",\"AllFlrsSF\",\"GrLivArea\",\"SimplOverallQual\",\"ExterQual\",\"GarageCars\",\"TotalBath\",\"KitchenQual\",\"GarageScore\",]\n",
    "\n",
    "    for df in (X_train, X_test):\n",
    "        for feat in feat1:\n",
    "            df[feat+'_2'] =  df[feat] ** 2\n",
    "            df[feat+'_3'] =  df[feat] ** 3\n",
    "            df[feat+'_sqrt'] =  np.sqrt(df[feat])\n",
    "            \n",
    "def add_log_features(X_train, X_test):\n",
    "    log_features = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                 'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                 'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                 'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                 'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','YearRemodAdd','TotalSF']\n",
    "\n",
    "    for df in (X_train, X_test):\n",
    "        for feat in log_features:\n",
    "            df[feat+'_log'] =  np.log1p(df[feat])\n",
    "\n",
    "def feature_engineer(data, ft_instructions=None):\n",
    "    X_train, y_train, X_test = data\n",
    "\n",
    "    if \"y_log\" in ft_instructions:\n",
    "        # Log-transform y_train\n",
    "        y_train = y_log(y_train)\n",
    "        \n",
    "    if \"order_categoricals\" in ft_instructions:\n",
    "        X_train = order_categoricals(X_train)\n",
    "        X_test = order_categoricals(X_test)\n",
    "        \n",
    "    if \"add_simplification_features\" in ft_instructions:\n",
    "        add_simplification_features(X_train, X_test)\n",
    "        \n",
    "    if \"add_totalizer_features\" in ft_instructions:\n",
    "        add_totalizer_features(X_train, X_test)\n",
    "        \n",
    "    if \"add_polynomial_features\" in ft_instructions:\n",
    "        add_polynomial_features(X_train, X_test)\n",
    "        \n",
    "    if \"add_log_features\" in ft_instructions:\n",
    "        add_log_features(X_train, X_test)\n",
    "        \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "def load_engineered_data(ft_instructions=None):\n",
    "    # Load the original data\n",
    "    X_train, y_train = load_train_data()\n",
    "    X_test, _ = load_test_data()\n",
    "    \n",
    "    X_train, y_train, X_test = feature_engineer((X_train, y_train, X_test), ft_instructions=ft_instructions)\n",
    "    \n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating feature engineering impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = load_train_data()\n",
    "# X_test, _ = load_test_data()\n",
    "\n",
    "# # y_train = y_log(y_train)\n",
    "# X_train = order_categoricals(X_train)\n",
    "# X_test = order_categoricals(X_test)\n",
    "\n",
    "# model = RandomForestRegressor()\n",
    "# pipe = get_pipe(model)\n",
    "# pipe.fit(X_train, y_train)    \n",
    "# y_pred = pipe.predict(X_test)\n",
    "\n",
    "# np.sort(y_pred)\n",
    "\n",
    "# score = kaggle_score(y_pred, y_log_transformed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature engineering\n",
    "#results = compare_models(models, feature_engineered=False)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_instructions = {\n",
    "#     \"y_log\": True\n",
    "# }\n",
    "# results = compare_models(models, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'RandomForestRegressor',\n",
       "  'kaggle_score': 0.14598928124918212,\n",
       "  'y_pred': array([11.73399268, 11.94003773, 12.11798064, ..., 11.9468015 ,\n",
       "         11.64755451, 12.36062206])},\n",
       " {'model': 'Ridge',\n",
       "  'kaggle_score': 0.14172924822618732,\n",
       "  'y_pred': array([11.67581985, 11.92327905, 12.06540916, ..., 11.98277   ,\n",
       "         11.64675014, 12.30735373])},\n",
       " {'model': 'RidgeCV',\n",
       "  'kaggle_score': 0.13455135630372234,\n",
       "  'y_pred': array([11.6312517 , 11.91317045, 12.03709099, ..., 11.95916254,\n",
       "         11.64971265, 12.33092812])},\n",
       " {'model': 'KernelRidge',\n",
       "  'kaggle_score': 0.16738800901178202,\n",
       "  'y_pred': array([11.70327424, 11.86258431, 12.06913926, ..., 11.96326104,\n",
       "         11.71512901, 12.35705814])},\n",
       " {'model': 'LassoCV',\n",
       "  'kaggle_score': 0.1328939189149408,\n",
       "  'y_pred': array([11.65748388, 11.90985259, 12.05391393, ..., 12.00426402,\n",
       "         11.68730082, 12.35507038])},\n",
       " {'model': 'ElasticNet',\n",
       "  'kaggle_score': 0.41637366760951144,\n",
       "  'y_pred': array([12.0240509, 12.0240509, 12.0240509, ..., 12.0240509, 12.0240509,\n",
       "         12.0240509])},\n",
       " {'model': 'SGDRegressor',\n",
       "  'kaggle_score': 0.257661819889787,\n",
       "  'y_pred': array([11.61220171, 12.38178084, 12.04687041, ..., 11.87166358,\n",
       "         11.79323402, 12.57737823])},\n",
       " {'model': 'LGBMRegressor',\n",
       "  'kaggle_score': 0.1300907541846932,\n",
       "  'y_pred': array([11.7074611 , 11.94646994, 12.125439  , ..., 12.03559555,\n",
       "         11.67914505, 12.26442933])},\n",
       " {'model': 'XGBRegressor',\n",
       "  'kaggle_score': 0.1434076124566207,\n",
       "  'y_pred': array([11.727846, 12.01457 , 12.151179, ..., 12.08726 , 11.694431,\n",
       "         12.319426], dtype=float32)}]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_instructions = {\n",
    "    \"y_log\": True,\n",
    "    \"order_categoricals\": True,\n",
    "}\n",
    "results = compare_models(models, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'RandomForestRegressor',\n",
       "  'kaggle_score': 0.14639924848063146,\n",
       "  'y_pred': array([11.7351833 , 11.9341645 , 12.11718869, ..., 11.95182489,\n",
       "         11.63407876, 12.3495651 ])},\n",
       " {'model': 'Ridge',\n",
       "  'kaggle_score': 0.1407874473073016,\n",
       "  'y_pred': array([11.68367067, 11.91446662, 12.07569246, ..., 11.99354933,\n",
       "         11.66295435, 12.31294374])},\n",
       " {'model': 'RidgeCV',\n",
       "  'kaggle_score': 0.13413926912035126,\n",
       "  'y_pred': array([11.64137565, 11.90523879, 12.04631661, ..., 11.97339152,\n",
       "         11.66681574, 12.33685116])},\n",
       " {'model': 'KernelRidge',\n",
       "  'kaggle_score': 0.16719986489353866,\n",
       "  'y_pred': array([11.71832662, 11.84694121, 12.07954181, ..., 11.96550278,\n",
       "         11.73549606, 12.36360486])},\n",
       " {'model': 'LassoCV',\n",
       "  'kaggle_score': 0.1322638661291602,\n",
       "  'y_pred': array([11.65678435, 11.90651468, 12.05997392, ..., 12.01474246,\n",
       "         11.68911524, 12.3559875 ])},\n",
       " {'model': 'ElasticNet',\n",
       "  'kaggle_score': 0.41637366760951144,\n",
       "  'y_pred': array([12.0240509, 12.0240509, 12.0240509, ..., 12.0240509, 12.0240509,\n",
       "         12.0240509])},\n",
       " {'model': 'SGDRegressor',\n",
       "  'kaggle_score': 0.26965899015047184,\n",
       "  'y_pred': array([11.65739196, 12.47191044, 12.04597984, ..., 11.85196302,\n",
       "         11.879244  , 12.59302653])},\n",
       " {'model': 'LGBMRegressor',\n",
       "  'kaggle_score': 0.1300907541846932,\n",
       "  'y_pred': array([11.7074611 , 11.94646994, 12.125439  , ..., 12.03559555,\n",
       "         11.67914505, 12.26442933])},\n",
       " {'model': 'XGBRegressor',\n",
       "  'kaggle_score': 0.1434076124566207,\n",
       "  'y_pred': array([11.727846, 12.01457 , 12.151179, ..., 12.08726 , 11.694431,\n",
       "         12.319426], dtype=float32)}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_instructions = {\n",
    "    \"y_log\": True,\n",
    "    \"order_categoricals\": True,\n",
    "    \"add_simplification_features\": True,\n",
    "}\n",
    "results = compare_models(models, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'RandomForestRegressor',\n",
       "  'kaggle_score': 0.138712548328831,\n",
       "  'y_pred': array([11.78699949, 11.98412446, 12.07516864, ..., 12.01253465,\n",
       "         11.6302134 , 12.33603119])},\n",
       " {'model': 'Ridge',\n",
       "  'kaggle_score': 0.1911016730097794,\n",
       "  'y_pred': array([11.69044588, 11.92309405, 12.09474908, ..., 12.03374006,\n",
       "         11.66797855, 12.32626468])},\n",
       " {'model': 'RidgeCV',\n",
       "  'kaggle_score': 0.2029865480462114,\n",
       "  'y_pred': array([11.66584599, 11.92483381, 12.0721491 , ..., 12.02142747,\n",
       "         11.68192706, 12.34493738])},\n",
       " {'model': 'KernelRidge',\n",
       "  'kaggle_score': 0.186974709967823,\n",
       "  'y_pred': array([11.71077477, 11.82594843, 12.09405644, ..., 11.99165478,\n",
       "         11.72807191, 12.37157547])},\n",
       " {'model': 'LassoCV',\n",
       "  'kaggle_score': 0.20487741221691252,\n",
       "  'y_pred': array([11.67197944, 11.91615369, 12.07518646, ..., 12.03275375,\n",
       "         11.69225193, 12.35557855])},\n",
       " {'model': 'ElasticNet',\n",
       "  'kaggle_score': 0.41637366760951144,\n",
       "  'y_pred': array([12.0240509, 12.0240509, 12.0240509, ..., 12.0240509, 12.0240509,\n",
       "         12.0240509])},\n",
       " {'model': 'SGDRegressor',\n",
       "  'kaggle_score': 30.099155802226157,\n",
       "  'y_pred': array([  7.8935242 , -70.27684882,  -2.47038326, ...,  31.72900039,\n",
       "          11.76198807,   1.67598681])},\n",
       " {'model': 'LGBMRegressor',\n",
       "  'kaggle_score': 0.13013117703198068,\n",
       "  'y_pred': array([11.77038148, 11.9857915 , 12.05905151, ..., 11.89081828,\n",
       "         11.62508774, 12.26901636])},\n",
       " {'model': 'XGBRegressor',\n",
       "  'kaggle_score': 0.1380447955649236,\n",
       "  'y_pred': array([11.751442 , 12.002411 , 12.104322 , ..., 11.975681 , 11.6131525,\n",
       "         12.22619  ], dtype=float32)}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_instructions = {\n",
    "    \"y_log\": True,\n",
    "    \"order_categoricals\": True,\n",
    "    \"add_simplification_features\": True,\n",
    "    \"add_totalizer_features\": True,\n",
    "}\n",
    "results = compare_models(models, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7357781686947895, tolerance: 0.02328006589886511\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'RandomForestRegressor',\n",
       "  'kaggle_score': 0.13865219369039805,\n",
       "  'y_pred': array([11.78228181, 11.98201328, 12.07799669, ..., 12.00889234,\n",
       "         11.62020881, 12.32166327])},\n",
       " {'model': 'Ridge',\n",
       "  'kaggle_score': 0.14461401381560612,\n",
       "  'y_pred': array([11.65693993, 11.96373572, 12.13146378, ..., 12.05211249,\n",
       "         11.69960528, 12.31993642])},\n",
       " {'model': 'RidgeCV',\n",
       "  'kaggle_score': 0.12797769148430285,\n",
       "  'y_pred': array([11.64224153, 11.96654369, 12.1111276 , ..., 12.04378108,\n",
       "         11.69178079, 12.33533097])},\n",
       " {'model': 'KernelRidge',\n",
       "  'kaggle_score': 0.15714337864695488,\n",
       "  'y_pred': array([11.67327329, 11.86084317, 12.12922929, ..., 12.0059282 ,\n",
       "         11.76319202, 12.36469014])},\n",
       " {'model': 'LassoCV',\n",
       "  'kaggle_score': 0.12460243637503508,\n",
       "  'y_pred': array([11.66243153, 11.95940421, 12.10856083, ..., 12.04682007,\n",
       "         11.69308973, 12.33956486])},\n",
       " {'model': 'ElasticNet',\n",
       "  'kaggle_score': 0.41637366760951144,\n",
       "  'y_pred': array([12.0240509, 12.0240509, 12.0240509, ..., 12.0240509, 12.0240509,\n",
       "         12.0240509])},\n",
       " {'model': 'SGDRegressor',\n",
       "  'kaggle_score': 11.185114023350751,\n",
       "  'y_pred': array([22.67575314,  3.9716038 , 11.71782251, ..., 12.73830456,\n",
       "         19.38827828, -8.13296305])},\n",
       " {'model': 'LGBMRegressor',\n",
       "  'kaggle_score': 0.13069346566659207,\n",
       "  'y_pred': array([11.75358856, 12.00604985, 12.02451423, ..., 11.93155882,\n",
       "         11.62976959, 12.24918162])},\n",
       " {'model': 'XGBRegressor',\n",
       "  'kaggle_score': 0.1380447955649236,\n",
       "  'y_pred': array([11.751442 , 12.002411 , 12.104322 , ..., 11.975681 , 11.6131525,\n",
       "         12.22619  ], dtype=float32)}]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_instructions = {\n",
    "    \"y_log\": True,\n",
    "    \"order_categoricals\": True,\n",
    "    \"add_simplification_features\": True,\n",
    "    \"add_totalizer_features\": True,\n",
    "    \"add_polynomial_features\": True,\n",
    "}\n",
    "results = compare_models(models, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021740229264620936, tolerance: 0.01891283972369289\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.028236429524666207, tolerance: 0.01891283972369289\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03313480667810964, tolerance: 0.01891283972369289\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03535582123150505, tolerance: 0.01891283972369289\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.032451285625189286, tolerance: 0.01891283972369289\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0234829786413826, tolerance: 0.01891283972369289\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021928185817820633, tolerance: 0.018002422128285202\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020470315213788837, tolerance: 0.018002422128285202\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02057719552808379, tolerance: 0.018002422128285202\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02351796101343595, tolerance: 0.018002422128285202\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023962491247733197, tolerance: 0.01837384809099904\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.030907624096185415, tolerance: 0.01837384809099904\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043915063669450305, tolerance: 0.01837384809099904\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03607084142351091, tolerance: 0.01837384809099904\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03882061690543459, tolerance: 0.01900832386904732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04464836876353573, tolerance: 0.01900832386904732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020218041869586756, tolerance: 0.01900832386904732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.030431519141771446, tolerance: 0.01900832386904732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03420622262809303, tolerance: 0.01900832386904732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/andy/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12476998241412574, tolerance: 0.02328006589886511\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n",
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'RandomForestRegressor',\n",
       "  'kaggle_score': 0.1385494368222794,\n",
       "  'y_pred': array([11.7837215 , 11.98775351, 12.08737762, ..., 12.01212653,\n",
       "         11.63092447, 12.32810437]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a7698070>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a76985e0>)])),\n",
       "                  ('model', RandomForestRegressor(random_state=42))])},\n",
       " {'model': 'Ridge',\n",
       "  'kaggle_score': 0.14319190271811916,\n",
       "  'y_pred': array([11.65806483, 11.99590535, 12.15563903, ..., 12.07994744,\n",
       "         11.7244328 , 12.32692121]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a897d520>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a4a36d30>)])),\n",
       "                  ('model', Ridge())])},\n",
       " {'model': 'RidgeCV',\n",
       "  'kaggle_score': 0.12707186809699497,\n",
       "  'y_pred': array([11.63012632, 12.00276524, 12.13814292, ..., 12.06717856,\n",
       "         11.70982214, 12.34046669]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a8962160>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a896fbb0>)])),\n",
       "                  ('model', RidgeCV(alphas=array([ 0.1,  1. , 10. ])))])},\n",
       " {'model': 'KernelRidge',\n",
       "  'kaggle_score': 0.15830093476916338,\n",
       "  'y_pred': array([11.66799363, 11.92772215, 12.1610939 , ..., 12.05407052,\n",
       "         11.74065375, 12.3740613 ]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86ced99af0>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86ce7c2b20>)])),\n",
       "                  ('model', KernelRidge())])},\n",
       " {'model': 'LassoCV',\n",
       "  'kaggle_score': 0.1225717876008984,\n",
       "  'y_pred': array([11.65378216, 11.97600571, 12.12935428, ..., 12.05428699,\n",
       "         11.70156304, 12.34094756]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899d760>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899de50>)])),\n",
       "                  ('model', LassoCV())])},\n",
       " {'model': 'ElasticNet',\n",
       "  'kaggle_score': 0.41637366760951144,\n",
       "  'y_pred': array([12.0240509, 12.0240509, 12.0240509, ..., 12.0240509, 12.0240509,\n",
       "         12.0240509]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a8963d60>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a77c80a0>)])),\n",
       "                  ('model', ElasticNet())])},\n",
       " {'model': 'SGDRegressor',\n",
       "  'kaggle_score': 2.323166937384124,\n",
       "  'y_pred': array([ 7.91074851, 14.51776177, 11.22347029, ...,  9.1102605 ,\n",
       "         11.82476817, 15.5903843 ]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a5f01520>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a8975580>)])),\n",
       "                  ('model', SGDRegressor())])},\n",
       " {'model': 'LGBMRegressor',\n",
       "  'kaggle_score': 0.13176671280249164,\n",
       "  'y_pred': array([11.74138776, 12.03762752, 12.05483515, ..., 11.92578369,\n",
       "         11.60657881, 12.27139202]),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a77c8c40>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a77c8e80>)])),\n",
       "                  ('model', LGBMRegressor())])},\n",
       " {'model': 'XGBRegressor',\n",
       "  'kaggle_score': 0.1380447955649236,\n",
       "  'y_pred': array([11.751442 , 12.002411 , 12.104322 , ..., 11.975681 , 11.6131525,\n",
       "         12.22619  ], dtype=float32),\n",
       "  'fitted_estimator': Pipeline(steps=[('preprocessing',\n",
       "                   ColumnTransformer(n_jobs=-1,\n",
       "                                     transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('standard_scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899dfa0>),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('impute_missing_categorical_...\n",
       "                                colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                                importance_type='gain',\n",
       "                                interaction_constraints='',\n",
       "                                learning_rate=0.300000012, max_delta_step=0,\n",
       "                                max_depth=6, min_child_weight=1, missing=nan,\n",
       "                                monotone_constraints='()', n_estimators=100,\n",
       "                                n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                                subsample=1, tree_method='exact',\n",
       "                                validate_parameters=1, verbosity=None))])}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_instructions = {\n",
    "    \"y_log\": True,\n",
    "    \"order_categoricals\": True,\n",
    "    \"add_simplification_features\": True,\n",
    "    \"add_totalizer_features\": True,\n",
    "    \"add_polynomial_features\": True,\n",
    "    \"add_log_features\": True,\n",
    "}\n",
    "results = compare_models(models, feature_engineered=True, ft_instructions=ft_instructions)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved.\n",
      "Successfully submitted to House Prices: Advanced Regression Techniques\n"
     ]
    }
   ],
   "source": [
    "#y_pred = np.exp(results[-5][\"y_pred\"])\n",
    "#submit_score_to_kaggle(y_pred, \"LassoCV_feature_engineering\", \"LassoCV with feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessing', ColumnTransformer(n_jobs=-1,\n",
       "                     transformers=[('numeric',\n",
       "                                    Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('standard_scaler',\n",
       "                                                     StandardScaler())]),\n",
       "                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899d760>),\n",
       "                                   ('categorical',\n",
       "                                    Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                    ('standard_scaler',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899de50>)])),\n",
       "  ('model', LassoCV())],\n",
       " 'verbose': False,\n",
       " 'preprocessing': ColumnTransformer(n_jobs=-1,\n",
       "                   transformers=[('numeric',\n",
       "                                  Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('standard_scaler',\n",
       "                                                   StandardScaler())]),\n",
       "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899d760>),\n",
       "                                 ('categorical',\n",
       "                                  Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                  ('standard_scaler',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f86a899de50>)]),\n",
       " 'model': LassoCV(),\n",
       " 'preprocessing__n_jobs': -1,\n",
       " 'preprocessing__remainder': 'drop',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('numeric',\n",
       "   Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                    SimpleImputer(strategy='median')),\n",
       "                   ('standard_scaler', StandardScaler())]),\n",
       "   <sklearn.compose._column_transformer.make_column_selector at 0x7f86a899d760>),\n",
       "  ('categorical',\n",
       "   Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                    SimpleImputer(strategy='most_frequent')),\n",
       "                   ('standard_scaler', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   <sklearn.compose._column_transformer.make_column_selector at 0x7f86a899de50>)],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__numeric': Pipeline(steps=[('impute_missing_numeric_values',\n",
       "                  SimpleImputer(strategy='median')),\n",
       "                 ('standard_scaler', StandardScaler())]),\n",
       " 'preprocessing__categorical': Pipeline(steps=[('impute_missing_categorical_values',\n",
       "                  SimpleImputer(strategy='most_frequent')),\n",
       "                 ('standard_scaler', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'preprocessing__numeric__memory': None,\n",
       " 'preprocessing__numeric__steps': [('impute_missing_numeric_values',\n",
       "   SimpleImputer(strategy='median')),\n",
       "  ('standard_scaler', StandardScaler())],\n",
       " 'preprocessing__numeric__verbose': False,\n",
       " 'preprocessing__numeric__impute_missing_numeric_values': SimpleImputer(strategy='median'),\n",
       " 'preprocessing__numeric__standard_scaler': StandardScaler(),\n",
       " 'preprocessing__numeric__impute_missing_numeric_values__add_indicator': False,\n",
       " 'preprocessing__numeric__impute_missing_numeric_values__copy': True,\n",
       " 'preprocessing__numeric__impute_missing_numeric_values__fill_value': None,\n",
       " 'preprocessing__numeric__impute_missing_numeric_values__missing_values': nan,\n",
       " 'preprocessing__numeric__impute_missing_numeric_values__strategy': 'median',\n",
       " 'preprocessing__numeric__impute_missing_numeric_values__verbose': 0,\n",
       " 'preprocessing__numeric__standard_scaler__copy': True,\n",
       " 'preprocessing__numeric__standard_scaler__with_mean': True,\n",
       " 'preprocessing__numeric__standard_scaler__with_std': True,\n",
       " 'preprocessing__categorical__memory': None,\n",
       " 'preprocessing__categorical__steps': [('impute_missing_categorical_values',\n",
       "   SimpleImputer(strategy='most_frequent')),\n",
       "  ('standard_scaler', OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'preprocessing__categorical__verbose': False,\n",
       " 'preprocessing__categorical__impute_missing_categorical_values': SimpleImputer(strategy='most_frequent'),\n",
       " 'preprocessing__categorical__standard_scaler': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessing__categorical__impute_missing_categorical_values__add_indicator': False,\n",
       " 'preprocessing__categorical__impute_missing_categorical_values__copy': True,\n",
       " 'preprocessing__categorical__impute_missing_categorical_values__fill_value': None,\n",
       " 'preprocessing__categorical__impute_missing_categorical_values__missing_values': nan,\n",
       " 'preprocessing__categorical__impute_missing_categorical_values__strategy': 'most_frequent',\n",
       " 'preprocessing__categorical__impute_missing_categorical_values__verbose': 0,\n",
       " 'preprocessing__categorical__standard_scaler__categories': 'auto',\n",
       " 'preprocessing__categorical__standard_scaler__drop': None,\n",
       " 'preprocessing__categorical__standard_scaler__dtype': numpy.float64,\n",
       " 'preprocessing__categorical__standard_scaler__handle_unknown': 'ignore',\n",
       " 'preprocessing__categorical__standard_scaler__sparse': True,\n",
       " 'model__alphas': None,\n",
       " 'model__copy_X': True,\n",
       " 'model__cv': None,\n",
       " 'model__eps': 0.001,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__max_iter': 1000,\n",
       " 'model__n_alphas': 100,\n",
       " 'model__n_jobs': None,\n",
       " 'model__normalize': False,\n",
       " 'model__positive': False,\n",
       " 'model__precompute': 'auto',\n",
       " 'model__random_state': None,\n",
       " 'model__selection': 'cyclic',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': False}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-5][\"fitted_estimator\"].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
