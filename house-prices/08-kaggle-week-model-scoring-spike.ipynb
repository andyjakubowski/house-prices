{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from scipy import stats\n",
    "from pandas.plotting import scatter_matrix\n",
    "import subprocess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Kaggle submission file\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_df(y_pred):\n",
    "    X_test = load_x_test()\n",
    "    return pd.DataFrame(y_pred, index=X_test.index, columns=[\"SalePrice\"])\n",
    "\n",
    "def save_submission_file(y_pred, filename):\n",
    "    df = submission_df(y_pred)\n",
    "    path = \"./\" + filename\n",
    "\n",
    "    try:\n",
    "        df.to_csv(path)\n",
    "    except Exception:\n",
    "        print(\"Couldn’t save submission.\")\n",
    "    else:\n",
    "        print(\"Submission saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit score to Kaggle\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_score_to_kaggle(y_pred, filename, message):\n",
    "    save_submission_file(y_pred, filename)\n",
    "\n",
    "    completed_process = subprocess.run(\n",
    "        [\n",
    "            \"kaggle\",\n",
    "            \"competitions\",\n",
    "            \"submit\",\n",
    "            \"-c\",\n",
    "            \"house-prices-advanced-regression-techniques\",\n",
    "            \"-f\",\n",
    "            filename,\n",
    "            \"-m\",\n",
    "            message\n",
    "        ], \n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(completed_process.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Get training data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(split=True):\n",
    "    target = \"SalePrice\"\n",
    "    data = pd.read_csv(\"./train.csv\", index_col=\"Id\")\n",
    "    features = [column for column in data.columns if not column == target]\n",
    "    print(\"load_train_data: done\")\n",
    "    \n",
    "    if split:\n",
    "        return data[features], data[target]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Get test data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x_test():\n",
    "    return pd.read_csv(\"./test.csv\", index_col=\"Id\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_true():\n",
    "    y_test = pd.read_csv(\"./solution.csv\", index_col=\"Id\")\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(split=True):\n",
    "    X_test = pd.read_csv(\"./test.csv\", index_col=\"Id\")\n",
    "    y_test = load_y_true()\n",
    "    print(\"load_test_data: done\")\n",
    "    \n",
    "    if split:\n",
    "        return X_test, y_test\n",
    "    else:\n",
    "        return pd.concat([X_test, y_test], axis=\"columns\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_test_data: done\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_target(df):\n",
    "    target = \"SalePrice\"\n",
    "    features = [column for column in df.columns if not column == target]\n",
    "    return df[features], df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(X):\n",
    "    X = drop_attributes(X, threshold=0.05)\n",
    "    X = complete_missing_values(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_train_data():\n",
    "    X, y = load_train_data()\n",
    "    X, y = remove_outliers(X, y)\n",
    "    X = clean_data(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_data():\n",
    "    # Load data\n",
    "    df_train = load_train_data(split=False)\n",
    "    df_test = load_test_data(split=False)\n",
    "\n",
    "    # Drop attributes with a lot of missing values, fill remaining missing values\n",
    "    df_train = clean_data(df_train)\n",
    "    df_test = clean_data(df_test)\n",
    "\n",
    "    # Add labels so you can split the DataFrames later\n",
    "    df_train[\"Label\"] = \"Train\"\n",
    "    df_test[\"Label\"] = \"Test\"\n",
    "\n",
    "    # Concat train and test data\n",
    "    df_all_data = pd.concat([df_train, df_test])\n",
    "    df_all_data = encode_categorical_attributes(df_all_data)\n",
    "\n",
    "    # Split data back into separate DataFrames\n",
    "    df_train = df_all_data[df_all_data[\"Label_Train\"] == 1]\n",
    "    df_test = df_all_data[df_all_data[\"Label_Test\"] == 1]\n",
    "\n",
    "    # Drop the labels\n",
    "    df_train = df_train.drop([\"Label_Train\", \"Label_Test\"], axis=\"columns\")\n",
    "    df_test = df_test.drop([\"Label_Train\", \"Label_Test\"], axis=\"columns\")\n",
    "\n",
    "    X_train, y_train = split_features_target(df_train)\n",
    "    X_test, y_test = split_features_target(df_test)\n",
    "\n",
    "    X_train, y_train = remove_outliers(X_train, y_train)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_data_linear_regression():\n",
    "    # Load data\n",
    "    df_train = load_train_data(split=False)\n",
    "    df_test = load_test_data(split=False)\n",
    "\n",
    "    # Drop attributes with a lot of missing values, fill remaining missing values\n",
    "    df_train = clean_data(df_train)\n",
    "    df_test = clean_data(df_test)\n",
    "\n",
    "    # Add labels so you can split the DataFrames later\n",
    "    df_train[\"Label\"] = \"Train\"\n",
    "    df_test[\"Label\"] = \"Test\"\n",
    "\n",
    "    # Concat train and test data\n",
    "    df_all_data = pd.concat([df_train, df_test])\n",
    "    df_all_data = encode_categorical_attributes(df_all_data)\n",
    "\n",
    "    # Split data back into separate DataFrames\n",
    "    df_train = df_all_data[df_all_data[\"Label_Train\"] == 1]\n",
    "    df_test = df_all_data[df_all_data[\"Label_Test\"] == 1]\n",
    "\n",
    "    # Drop the labels\n",
    "    df_train = df_train.drop([\"Label_Train\", \"Label_Test\"], axis=\"columns\")\n",
    "    df_test = df_test.drop([\"Label_Train\", \"Label_Test\"], axis=\"columns\")\n",
    "\n",
    "    X_train, y_train = split_features_target(df_train)\n",
    "    X_test, y_test = split_features_target(df_test)\n",
    "\n",
    "    X_train, y_train = remove_outliers(X_train, y_train)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X, y):\n",
    "    # Remove the observations where GrLivArea is unusually high\n",
    "    outliers = X[X[\"GrLivArea\"] > 4000]\n",
    "    X = X.drop(outliers.index)\n",
    "    y = y.drop(outliers.index)\n",
    "    print(\"remove_outliers: done\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Drop attributes that have too many missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_info(df):\n",
    "    total = df.isnull().sum()\n",
    "    percentage = (total / len(df))\n",
    "    na_info = pd.concat([total, percentage], axis=\"columns\", keys=[\"Total\", \"Percentage\"])\n",
    "    return na_info.sort_values(by=\"Total\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_attributes(df, threshold=0.05):\n",
    "    missing_info = na_info(df)\n",
    "    columns_to_drop = missing_info[missing_info[\"Percentage\"] > threshold].index\n",
    "    print(f\"Dropping {len(columns_to_drop)} columns: {columns_to_drop}\")\n",
    "    return df.drop(columns_to_drop, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Fill in missing values or drop their rows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_missing_values(X):\n",
    "    X_num = X.select_dtypes(np.number)\n",
    "    X_cat = X.select_dtypes(object)\n",
    "    imp_num = SimpleImputer(strategy=\"median\")\n",
    "    imp_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "    array_num = imp_num.fit_transform(X_num)\n",
    "    array_cat = imp_cat.fit_transform(X_cat)\n",
    "    X_num_transformed = pd.DataFrame(array_num, columns=X_num.columns, index=X_num.index)\n",
    "    X_cat_transformed = pd.DataFrame(array_cat, columns=X_cat.columns, index=X_cat.index)\n",
    "    X_transformed = pd.concat([X_num_transformed, X_cat_transformed], axis=\"columns\")\n",
    "    print(\"complete_missing_values: done\")\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Drop attributes that don’t provide useful information for house price prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Check if any numerical continuous features should be discretized*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Discretize continuous features if needed*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Decompose categorical features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_attributes(X):\n",
    "    print(\"encode_categorical_attributes: done\")\n",
    "    return pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Add promising transformations of features (e.g., log( x ), sqrt( x ), x 2 , etc.).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Check if it would make sense to aggregate features into new features*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Aggregate features into new features, if it makes sense*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *If your model requires it, standardize or normalize features*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate score\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(y_true, y_pred, transform_negative_predictions=False):\n",
    "    if transform_negative_predictions:\n",
    "        y_pred_tr = [max(prediction, 0) for prediction in y_pred]\n",
    "    else:\n",
    "        y_pred_tr = y_pred\n",
    "    \n",
    "    # same as np.sqrt(np.mean(np.power(np.log(np.array(y_pred_tr) + 1) - np.log(np.array(y_true) + 1), 2)))\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred_tr))\n",
    "\n",
    "def kaggle_score(y_pred, transform_negative_predictions=False):\n",
    "    y_true = load_y_true()\n",
    "    score = root_mean_squared_log_error(y_true, y_pred, transform_negative_predictions=transform_negative_predictions)\n",
    "    return score\n",
    "\n",
    "def print_kaggle_score(y_pred):\n",
    "    y_true = load_y_true()\n",
    "    score = kaggle_score(y_pred)\n",
    "    print(\"The score is %.5f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "Dropping 11 columns: Index(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
      "       'GarageYrBlt', 'GarageCond', 'GarageType', 'GarageFinish',\n",
      "       'GarageQual'],\n",
      "      dtype='object')\n",
      "complete_missing_values: done\n",
      "Dropping 11 columns: Index(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
      "       'GarageFinish', 'GarageQual', 'GarageCond', 'GarageYrBlt',\n",
      "       'GarageType'],\n",
      "      dtype='object')\n",
      "complete_missing_values: done\n",
      "encode_categorical_attributes: done\n",
      "remove_outliers: done\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepped_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortlist Promising Models\n",
    "---\n",
    "\n",
    "- [todo] train many quick-and-dirty models using standard parameters\n",
    "- [todo] compute mean and standard deviation of n-fold cross validation performance\n",
    "- [todo] analyze the importances of attributes for each algorithm\n",
    "- [todo] analyze the types of errors the models make\n",
    "- [todo] do a quick round of feature selection and engineering\n",
    "- [todo] run one or two iterations of the past five steps \n",
    "- [todo] shortlist the top three models, preferring models making different errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    }
   ],
   "source": [
    "data_train = load_train_data(split=False)\n",
    "\n",
    "# Grab numerical attributes only\n",
    "data_train = data_train.select_dtypes(np.number)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "data_train_array = imp.fit_transform(data_train)\n",
    "data_train = pd.DataFrame(data_train_array, columns=data_train.columns, index=data_train.index)\n",
    "X_train, y_train = split_features_target(data_train)\n",
    "\n",
    "X_test, y_test = load_test_data()\n",
    "\n",
    "X_test = X_test.select_dtypes(np.number)\n",
    "imp_test = SimpleImputer(strategy=\"median\")\n",
    "X_test_array = imp_test.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_array, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634830"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = submission_df(y_pred)\n",
    "int(y_pred_df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484533797390255"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the estimator score using the estimator’s default metric, R2 score\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484533797390255"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that R2 score is the default scoring metric for LinearRegression\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20219.79505456269"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981920717.258501"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048715608332027115"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2207161261259066"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2207161261259066"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit_score_to_kaggle(y_pred, \"linear_regression_submission_01\", \"Plain numerical-features linear regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Linear Regression using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_data():\n",
    "    # Get training data\n",
    "    data_train = load_train_data(split=False)\n",
    "\n",
    "    # Grab numerical attributes only\n",
    "    data_train = data_train.select_dtypes(np.number)\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    data_train_array = imp.fit_transform(data_train)\n",
    "    data_train = pd.DataFrame(data_train_array, columns=data_train.columns, index=data_train.index)\n",
    "    X_train, y_train = split_features_target(data_train)\n",
    "\n",
    "    # Get test data\n",
    "    X_test, y_test = load_test_data()\n",
    "\n",
    "    X_test = X_test.select_dtypes(np.number)\n",
    "    imp_test = SimpleImputer(strategy=\"median\")\n",
    "    X_test_array = imp_test.fit_transform(X_test)\n",
    "    X_test = pd.DataFrame(X_test_array, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84586559, 0.81392047, 0.82245699, 0.81772022, 0.6291012 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you don’t specify a scoring parameter, the estimator’s default scorer (if available) is used\n",
    "# In the case of LinearRegression, that’s the R2 score\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination\n",
    "X_train, y_train, _, _ = regr_data()\n",
    "regr = LinearRegression()\n",
    "scores = cross_val_score(regr, X_train, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21734.00826107, 22179.79085408, 21384.20683081, 20465.68469093,\n",
       "       24264.8332824 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, _, _ = regr_data()\n",
    "regr = LinearRegression()\n",
    "scores = cross_val_score(regr, X_train, y_train, scoring=\"neg_mean_absolute_error\")\n",
    "-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 852768619, 1222667164, 1345385102,  923402939, 2487013526])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, _, _ = regr_data()\n",
    "regr = LinearRegression()\n",
    "scores = cross_val_score(regr, X_train, y_train, scoring=\"neg_mean_squared_error\")\n",
    "(-scores.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21734.00826107, 22179.79085408, 21384.20683081, 20465.68469093,\n",
       "       24264.8332824 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a scorer object with a built-in metric function\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "X_train, y_train, _, _ = regr_data()\n",
    "regr = LinearRegression()\n",
    "scores = cross_val_score(regr, X_train, y_train, scoring=mae_scorer)\n",
    "-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.17580936, 0.90945406, 0.18550033, 0.26147498, 0.19897854])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make your own RMSLE (root mean square log error) scorer\n",
    "rmsle_scorer = make_scorer(root_mean_squared_log_error, greater_is_better=False, transform_negative_predictions=True)\n",
    "\n",
    "X_train, y_train, _, _ = regr_data()\n",
    "regr = LinearRegression()\n",
    "scores = cross_val_score(regr, X_train, y_train, scoring=rmsle_scorer)\n",
    "-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_test_data: done\n",
      "Dropping 11 columns: Index(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
      "       'GarageYrBlt', 'GarageCond', 'GarageType', 'GarageFinish',\n",
      "       'GarageQual'],\n",
      "      dtype='object')\n",
      "complete_missing_values: done\n",
      "Dropping 11 columns: Index(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
      "       'GarageFinish', 'GarageQual', 'GarageCond', 'GarageYrBlt',\n",
      "       'GarageType'],\n",
      "      dtype='object')\n",
      "complete_missing_values: done\n",
      "encode_categorical_attributes: done\n",
      "remove_outliers: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.14050525, 0.1422873 , 0.1446216 , 0.13735748, 0.14099424])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepped_data()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rmsle_scorer = make_scorer(root_mean_squared_log_error, greater_is_better=False)\n",
    "scores = cross_val_score(rf, X_train, y_train, scoring=rmsle_scorer)\n",
    "-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14645785296396835"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "kaggle_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>179004.597087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73528.918675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>58030.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>130545.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>157190.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>209799.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>549460.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SalePrice\n",
       "count    1459.000000\n",
       "mean   179004.597087\n",
       "std     73528.918675\n",
       "min     58030.100000\n",
       "25%    130545.495000\n",
       "50%    157190.220000\n",
       "75%    209799.845000\n",
       "max    549460.120000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = submission_df(y_pred)\n",
    "y_pred_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
